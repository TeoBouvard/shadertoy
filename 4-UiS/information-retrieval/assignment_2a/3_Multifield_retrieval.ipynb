{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2A, Part 3: Multifield retrieval\n",
    "\n",
    "Implement BM25F and the Mixture of Language Models (MLM). Use two fields: title and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from hashedindex import textparser\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "N_GRAMS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = load_file('data/basic_index_new_idf.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030547"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index['content_doc_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the queries from the file\n",
    "\n",
    "See the assignment description for the format of the query file [here](https://github.com/kbalog/uis-dat640-fall2019/tree/master/assignments/assignment-2a#queries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_FILE = \"data/queries.txt\"  # make sure the query file exists on this location\n",
    "BM25_OUTPUT_FILE = \"data/bm25_multifield.txt\"  # output the ranking\n",
    "MLM_OUTPUT_FILE = \"data/lm_multifield.txt\"  # output the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries(query_file):\n",
    "    queries = {}\n",
    "    with open(query_file, \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            qid, query = line.strip().split(\" \", 1)\n",
    "            queries[qid] = query\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries(QUERY_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25F():\n",
    "    \n",
    "    def __init__(self, index, w_title = 0.2, k1 = 1.2, b_title = 0.75, b_content = 0.75):\n",
    "        self.k1 = k1\n",
    "        self.b_title = b_title\n",
    "        self.b_content = b_content\n",
    "        self.w_title = w_title\n",
    "        self.w_content = 1-w_title\n",
    "        \n",
    "        self.content_index = index['content_index']\n",
    "        self.title_index = index['title_index']\n",
    "        \n",
    "        # combine different idf ?\n",
    "        self.content_idf = index['content_idf']\n",
    "        self.title_idf = index['title_idf']\n",
    "        \n",
    "        self.content_doc_length = index['content_doc_length']\n",
    "        self.title_doc_length = index['title_doc_length']\n",
    "        self.average_content_length = index['average_content_length']\n",
    "        self.average_title_length = index['average_title_length']\n",
    "        \n",
    "\n",
    "    \n",
    "    def rank_query(self, query):\n",
    "        \n",
    "        # tokenize with nltk tokenizer because it works well\n",
    "        query = ' '.join([word for word in word_tokenize(query)])\n",
    "        \n",
    "        ranking = Counter()\n",
    "        \n",
    "        # tokenize a second time with hashedindex tokenizer to have tuple tokens\n",
    "        for token in textparser.word_tokenize(query, stopwords=stopwords, ngrams=N_GRAMS):\n",
    "            if token in self.content_index or token in self.title_index:\n",
    "                \n",
    "                documents = self.content_index.get_documents(token)\n",
    "                titles = self.title_index.get_documents(token)\n",
    "                #print('\"{}\" appears in {} documents'.format(token, len(documents)))   \n",
    "                \n",
    "                ranking += Counter(self.rank_term(token, documents, titles))\n",
    "            else:\n",
    "                print(token, 'is not in the index')   \n",
    "        \n",
    "        return ranking.most_common(100)\n",
    "    \n",
    "        \n",
    "    def rank_term(self, term, documents, titles):\n",
    "        # here we use a dictionnary because adding counters is a slow operation compared to dictionnary access\n",
    "        pseudo_content = {}\n",
    "        pseudo_title = {}\n",
    "        \n",
    "        for doc in documents:\n",
    "            content_tf = self.content_index.get_term_frequency(term, doc) # not normalized ! \n",
    "            content_smoothing = 1 - self.b_content + self.b_content * (self.content_doc_length[doc]/self.average_content_length)         \n",
    "            content_score = (content_tf*(1+self.k1)) / (content_tf + self.k1 * content_smoothing)\n",
    "            pseudo_content[doc] = self.w_content * content_score\n",
    "            \n",
    "        for title in titles:\n",
    "            title_tf = self.title_index.get_term_frequency(term, title) # not normalized !\n",
    "            title_smoothing = 1 - self.b_title + self.b_title * (self.title_doc_length[title]/self.average_title_length)\n",
    "            title_score = (title_tf*(1+self.k1)) / (title_tf + self.k1 * content_smoothing)\n",
    "            pseudo_title[title] = self.w_title * title_score\n",
    "        \n",
    "        pseudo_all = self.merge_dicts(pseudo_content, pseudo_title)\n",
    "            \n",
    "        document_scores = {doc_id:score * (self.content_idf[term] + self.title_idf[term]) for doc_id, score in pseudo_all.items()}\n",
    "            \n",
    "        return document_scores\n",
    "    \n",
    "    def merge_dicts(self, dictA, dictB):\n",
    "        for key, item in dictB.items():\n",
    "            dictA[key] = dictA.get(key, 0) + item\n",
    "        return dictA\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLM():\n",
    "    \n",
    "    def __init__(self, index, smoothing='jelinek', w_title=0.5, lambda_param=0.1, mu_param=1000):\n",
    "        \n",
    "        if smoothing == 'jelinek':\n",
    "            self.lambda_param = lambda_param\n",
    "        elif smoothing == 'dirichlet':\n",
    "            self.mu_param = mu_param\n",
    "        else:\n",
    "            raise ValueError('smoothing should in [jelinek, dirichlet]')\n",
    "            \n",
    "        self.smoothing = smoothing\n",
    "        self.w_title = w_title\n",
    "        self.w_content = 1-w_title\n",
    "        \n",
    "        self.content_index = index['content_index']\n",
    "        self.title_index = index['title_index']\n",
    "        \n",
    "        self.content_doc_length = index['content_doc_length']\n",
    "        self.title_doc_length = index['title_doc_length']\n",
    "        \n",
    "        self.content_sum_tf = index['content_sum_tf']\n",
    "        self.title_sum_tf = index['title_sum_tf']\n",
    "        \n",
    "        self.content_sum_length = index['content_sum_length']\n",
    "        self.title_sum_length = index['title_sum_length']\n",
    "        \n",
    "        self.content_collection_probability = index['content_collection_probability']\n",
    "        self.title_collection_probability = index['title_collection_probability']\n",
    "        \n",
    "    \n",
    "    def rank_query(self, query):\n",
    "        query = ' '.join([word for word in word_tokenize(query)])\n",
    "        \n",
    "        # we can't use counter objects to track scores because it does not support negative addition\n",
    "        ranking = {}\n",
    "        \n",
    "        for token in textparser.word_tokenize(query, stopwords=stopwords, ngrams=N_GRAMS):\n",
    "            if token in self.content_index or token in self.title_index:\n",
    "                \n",
    "                documents = self.content_index.get_documents(token)\n",
    "                titles = self.title_index.get_documents(token)\n",
    "                #print('\"{}\" appears in {} documents'.format(token, len(documents)))\n",
    "                \n",
    "                if self.smoothing == 'jelinek':\n",
    "                    ranking = self.merge_rankings(ranking, self.rank_term_jelinek(token, documents, titles))\n",
    "                elif self.smoothing == 'dirichlet':\n",
    "                    ranking = self.merge_rankings(ranking, self.rank_term_dirichlet(token, documents, titles))\n",
    "                \n",
    "            else:\n",
    "                print(token, 'is not in the index')\n",
    "                \n",
    "        return sorted(ranking.items(), key=lambda x: x[1])[:100]\n",
    "        \n",
    "    def rank_term_jelinek(self, term, documents, titles):\n",
    "        title_scores = {}\n",
    "        document_scores = {}\n",
    "        \n",
    "        for doc in documents:\n",
    "            ptd = self.content_index.get_term_frequency(term, doc, normalized=True)\n",
    "            ptc = self.content_collection_probability[term]\n",
    "            score = ((1 - self.lambda_param) * ptd) + (self.lambda_param * ptc)\n",
    "            document_scores[doc] = self.w_content * math.log(score)\n",
    "        \n",
    "        for title in titles:\n",
    "            ptd = self.title_index.get_term_frequency(term, title, normalized=True)\n",
    "            ptc = self.title_collection_probability[term]\n",
    "            score = ((1 - self.lambda_param) * ptd) + (self.lambda_param * ptc)\n",
    "            title_scores[title] = self. w_title * math.log(score)\n",
    "\n",
    "        return self.merge_rankings(title_scores, document_scores)\n",
    "    \n",
    "    def rank_term_dirichlet(self, term, documents, titles):\n",
    "        title_scores = {}\n",
    "        document_scores = {}\n",
    "        \n",
    "        for doc in documents:\n",
    "            tf = self.content_index.get_term_frequency(term, doc, normalized=True)\n",
    "            ptc = self.content_collection_probability[term]\n",
    "            score = (tf + self.mu_param*ptc) / (self.content_doc_length[doc] + self.mu_param)\n",
    "            document_scores[doc] = self.w_content * score\n",
    "            \n",
    "        for title in titles:\n",
    "            tf = self.title_index.get_term_frequency(term, title, normalized=True)\n",
    "            ptc = self.title_collection_probability[term]\n",
    "            score = (tf + self.mu_param*ptc) / (self.title_doc_length[title] + self.mu_param)\n",
    "            title_scores[title] = self.w_title * score\n",
    "            \n",
    "        for doc_id, score in title_scores:\n",
    "            document_scores[doc_id] = math.log(document_scores.get(doc_id, 0) + score)\n",
    "            \n",
    "        return self.merge_rankings(title_scores, document_scores)\n",
    "\n",
    "    def merge_rankings(self, base_ranking, to_add):\n",
    "        for doc, score in to_add.items():\n",
    "            base_ranking[doc] = base_ranking.get(doc, 0) + score\n",
    "        return base_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Generate a ranking for each query and output the results to `OUTPUT_FILE`\n",
    "\n",
    "See the assignment description for the format of the output file [here](https://github.com/kbalog/uis-dat640-fall2019/tree/master/assignments/assignment-2a#output-file-format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking documents for [303] 'Hubble Telescope Achievements'\n",
      "Ranking documents for [307] 'New Hydroelectric Projects'\n",
      "Ranking documents for [310] 'Radio Waves and Brain Cancer'\n",
      "Ranking documents for [314] 'Marine Vegetation'\n",
      "Ranking documents for [322] 'International Art Crime'\n",
      "Ranking documents for [325] 'Cult Lifestyles'\n",
      "Ranking documents for [330] 'Iran-Iraq Cooperation'\n",
      "Ranking documents for [336] 'Black Bear Attacks'\n",
      "Ranking documents for [341] 'Airport Security'\n",
      "Ranking documents for [344] 'Abuses of E-Mail'\n",
      "Ranking documents for [345] 'Overseas Tobacco Sales'\n",
      "Ranking documents for [347] 'Wildlife Extinction'\n",
      "Ranking documents for [353] 'Antarctica exploration'\n",
      "Ranking documents for [354] 'journalist risks'\n",
      "Ranking documents for [362] 'human smuggling'\n",
      "Ranking documents for [363] 'transportation tunnel disasters'\n",
      "Ranking documents for [367] 'piracy'\n",
      "Ranking documents for [372] 'Native American casino'\n",
      "Ranking documents for [374] 'Nobel prize winners'\n",
      "Ranking documents for [375] 'hydrogen energy'\n",
      "Ranking documents for [378] 'euro opposition'\n",
      "Ranking documents for [383] 'mental illness drugs'\n",
      "Ranking documents for [389] 'illegal technology transfer'\n",
      "Ranking documents for [393] 'mercy killing'\n",
      "Ranking documents for [394] 'home schooling'\n",
      "Ranking documents for [397] 'automobile recalls'\n",
      "Ranking documents for [399] 'oceanographic vessels'\n",
      "Ranking documents for [401] 'foreign minorities, Germany'\n",
      "Ranking documents for [404] 'Ireland, peace talks'\n",
      "Ranking documents for [408] 'tropical storms'\n",
      "Ranking documents for [409] 'legal, Pan Am, 103'\n",
      "Ranking documents for [416] 'Three Gorges Project'\n",
      "Ranking documents for [419] 'recycle, automobile tires'\n",
      "Ranking documents for [426] 'law enforcement, dogs'\n",
      "Ranking documents for [427] 'UV damage, eyes'\n",
      "Ranking documents for [433] 'Greek, philosophy, stoicism'\n",
      "Ranking documents for [435] 'curbing population growth'\n",
      "Ranking documents for [436] 'railway accidents'\n",
      "Ranking documents for [439] 'inventions, scientific discoveries'\n",
      "Ranking documents for [443] 'U.S., investment, Africa'\n",
      "Ranking documents for [448] 'ship losses'\n",
      "Ranking documents for [622] 'price fixing'\n",
      "Ranking documents for [625] 'arrests bombing WTC'\n",
      "Ranking documents for [638] 'wrongful convictions'\n",
      "Ranking documents for [639] 'consumer on-line shopping'\n",
      "Ranking documents for [648] 'family leave law'\n",
      "Ranking documents for [650] 'tax evasion indicted'\n",
      "Ranking documents for [651] 'U.S. ethnic population'\n",
      "Ranking documents for [658] 'teenage pregnancy'\n",
      "Ranking documents for [689] 'family-planning aid'\n"
     ]
    }
   ],
   "source": [
    "bm25 = BM25F(index, w_title=0.1, k1=1, b_content=0.29, b_title=0.2)\n",
    "\n",
    "with open(BM25_OUTPUT_FILE, 'w') as f:\n",
    "    f.write('QueryId,DocumentId\\n')\n",
    "    \n",
    "    for q_id, query in queries.items():\n",
    "        \n",
    "        print(\"Ranking documents for [%s] '%s'\" % (q_id, query))\n",
    "        ranking = bm25.rank_query(query)\n",
    "        f.writelines(['{},{}\\n'.format(q_id, document[0], '\\n') for document in ranking])\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25F_parameters_gridsearch(w_start = 0.2, w_stop = 0.3, w_step = 0.1, k_start=1.0, k_stop=1.3, k_step=0.1, b_content_start=0.0, b_content_stop=1.1, b_title_start=0.0, b_title_stop=1.1, b_step=0.1):\n",
    "    w_range = np.arange(w_start, w_stop, w_step)\n",
    "    k_range = np.arange(k_start, k_stop, k_step)\n",
    "    b_content_range = np.arange(b_content_start, b_content_stop, b_step)\n",
    "    b_title_range = np.arange(b_title_start, b_title_stop, b_step)\n",
    "    grid = itertools.product(w_range, k_range, b_content_range, b_title_range)\n",
    "    \n",
    "    for w, k, bc, bt in grid:\n",
    "        print(w, k, bc, bt)\n",
    "        model = BM25F(index, w_title=w, k1=k, b_content=bc, b_title=bt)\n",
    "        with open('data/gridsearch_BM25F_w{:.3}_k{:.3}_bc{:.3}_bt{:.3}.txt'.format(w, k, bc, bt), 'w') as f:\n",
    "            f.write('QueryId,DocumentId\\n')\n",
    "\n",
    "            for q_id, query in queries.items():\n",
    "                ranking = model.rank_query(query)\n",
    "                f.writelines(['{},{}\\n'.format(q_id, document[0], '\\n') for document in ranking])\n",
    "                f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 1.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "BM25F_parameters_gridsearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking documents for [303] 'Hubble Telescope Achievements'\n",
      "Ranking documents for [307] 'New Hydroelectric Projects'\n",
      "Ranking documents for [310] 'Radio Waves and Brain Cancer'\n",
      "Ranking documents for [314] 'Marine Vegetation'\n",
      "Ranking documents for [322] 'International Art Crime'\n",
      "Ranking documents for [325] 'Cult Lifestyles'\n",
      "Ranking documents for [330] 'Iran-Iraq Cooperation'\n",
      "Ranking documents for [336] 'Black Bear Attacks'\n",
      "Ranking documents for [341] 'Airport Security'\n",
      "Ranking documents for [344] 'Abuses of E-Mail'\n",
      "Ranking documents for [345] 'Overseas Tobacco Sales'\n",
      "Ranking documents for [347] 'Wildlife Extinction'\n",
      "Ranking documents for [353] 'Antarctica exploration'\n",
      "Ranking documents for [354] 'journalist risks'\n",
      "Ranking documents for [362] 'human smuggling'\n",
      "Ranking documents for [363] 'transportation tunnel disasters'\n",
      "Ranking documents for [367] 'piracy'\n",
      "Ranking documents for [372] 'Native American casino'\n",
      "Ranking documents for [374] 'Nobel prize winners'\n",
      "Ranking documents for [375] 'hydrogen energy'\n",
      "Ranking documents for [378] 'euro opposition'\n",
      "Ranking documents for [383] 'mental illness drugs'\n",
      "Ranking documents for [389] 'illegal technology transfer'\n",
      "Ranking documents for [393] 'mercy killing'\n",
      "Ranking documents for [394] 'home schooling'\n",
      "Ranking documents for [397] 'automobile recalls'\n",
      "Ranking documents for [399] 'oceanographic vessels'\n",
      "Ranking documents for [401] 'foreign minorities, Germany'\n",
      "Ranking documents for [404] 'Ireland, peace talks'\n",
      "Ranking documents for [408] 'tropical storms'\n",
      "Ranking documents for [409] 'legal, Pan Am, 103'\n",
      "Ranking documents for [416] 'Three Gorges Project'\n",
      "Ranking documents for [419] 'recycle, automobile tires'\n",
      "Ranking documents for [426] 'law enforcement, dogs'\n",
      "Ranking documents for [427] 'UV damage, eyes'\n",
      "Ranking documents for [433] 'Greek, philosophy, stoicism'\n",
      "Ranking documents for [435] 'curbing population growth'\n",
      "Ranking documents for [436] 'railway accidents'\n",
      "Ranking documents for [439] 'inventions, scientific discoveries'\n",
      "Ranking documents for [443] 'U.S., investment, Africa'\n",
      "Ranking documents for [448] 'ship losses'\n",
      "Ranking documents for [622] 'price fixing'\n",
      "Ranking documents for [625] 'arrests bombing WTC'\n",
      "Ranking documents for [638] 'wrongful convictions'\n",
      "Ranking documents for [639] 'consumer on-line shopping'\n",
      "Ranking documents for [648] 'family leave law'\n",
      "Ranking documents for [650] 'tax evasion indicted'\n",
      "Ranking documents for [651] 'U.S. ethnic population'\n",
      "Ranking documents for [658] 'teenage pregnancy'\n",
      "Ranking documents for [689] 'family-planning aid'\n"
     ]
    }
   ],
   "source": [
    "mlm = MLM(index, smoothing='jelinek', w_title=0.2, lambda_param=1)\n",
    "\n",
    "with open(MLM_OUTPUT_FILE, 'w') as f:\n",
    "    f.write('QueryId,DocumentId\\n')\n",
    "    \n",
    "    for q_id, query in queries.items():\n",
    "        \n",
    "        print(\"Ranking documents for [%s] '%s'\" % (q_id, query))\n",
    "        ranking = mlm.rank_query(query)\n",
    "        f.writelines(['{},{}\\n'.format(q_id, document[0], '\\n') for document in ranking])\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLM_parameters_gridsearch(w_start = 0.0, w_stop = 1.1, w_step = 0.1, lambda_start = 0.0, lambda_stop = 1.1, lambda_step = 0.1, mu_start=1, mu_stop=10000, n_mu=8):\n",
    "    smoothings = ['jelinek', 'dirichlet']\n",
    "    lambda_range = np.arange(lambda_start, lambda_stop, lambda_step)\n",
    "    w_range = np.arange(w_start, w_stop, w_step)\n",
    "    mu_range = np.linspace(mu_start, mu_stop, n_mu)\n",
    "    grid = [[smoothings[0], param] for param in lambda_range] + [[smoothings[1], param] for param in mu_range]\n",
    "    grid = itertools.product(w_range, grid)\n",
    "    \n",
    "    for w, params in grid:\n",
    "        print(w, params[0], params[1])\n",
    "        model = MLM(index, w_title=w, smoothing=params[0], lambda_param=params[1], mu_param=params[1])\n",
    "        with open('data/gridsearch_mlm_w{:.3}_s{:.3}_param{:.3}.txt'.format(w, params[0], params[1]), 'w') as f:\n",
    "            f.write('QueryId,DocumentId\\n')\n",
    "\n",
    "            for q_id, query in queries.items():\n",
    "                ranking = model.rank_query(query)\n",
    "                f.writelines(['{},{}\\n'.format(q_id, document[0], '\\n') for document in ranking])\n",
    "                f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 jelinek 0.0\n",
      "0.0 jelinek 0.1\n",
      "0.0 jelinek 0.2\n",
      "0.0 jelinek 0.30000000000000004\n",
      "0.0 jelinek 0.4\n",
      "0.0 jelinek 0.5\n",
      "0.0 jelinek 0.6000000000000001\n",
      "0.0 jelinek 0.7000000000000001\n",
      "0.0 jelinek 0.8\n",
      "0.0 jelinek 0.9\n",
      "0.0 jelinek 1.0\n",
      "0.0 dirichlet 1.0\n",
      "0.0 dirichlet 1429.4285714285713\n",
      "0.0 dirichlet 2857.8571428571427\n",
      "0.0 dirichlet 4286.285714285714\n",
      "0.0 dirichlet 5714.714285714285\n",
      "0.0 dirichlet 7143.142857142857\n",
      "0.0 dirichlet 8571.571428571428\n",
      "0.0 dirichlet 10000.0\n",
      "0.1 jelinek 0.0\n",
      "0.1 jelinek 0.1\n",
      "0.1 jelinek 0.2\n",
      "0.1 jelinek 0.30000000000000004\n",
      "0.1 jelinek 0.4\n",
      "0.1 jelinek 0.5\n",
      "0.1 jelinek 0.6000000000000001\n",
      "0.1 jelinek 0.7000000000000001\n",
      "0.1 jelinek 0.8\n",
      "0.1 jelinek 0.9\n",
      "0.1 jelinek 1.0\n",
      "0.1 dirichlet 1.0\n",
      "0.1 dirichlet 1429.4285714285713\n",
      "0.1 dirichlet 2857.8571428571427\n",
      "0.1 dirichlet 4286.285714285714\n",
      "0.1 dirichlet 5714.714285714285\n",
      "0.1 dirichlet 7143.142857142857\n",
      "0.1 dirichlet 8571.571428571428\n",
      "0.1 dirichlet 10000.0\n",
      "0.2 jelinek 0.0\n",
      "0.2 jelinek 0.1\n",
      "0.2 jelinek 0.2\n",
      "0.2 jelinek 0.30000000000000004\n",
      "0.2 jelinek 0.4\n",
      "0.2 jelinek 0.5\n",
      "0.2 jelinek 0.6000000000000001\n",
      "0.2 jelinek 0.7000000000000001\n",
      "0.2 jelinek 0.8\n",
      "0.2 jelinek 0.9\n",
      "0.2 jelinek 1.0\n",
      "0.2 dirichlet 1.0\n",
      "0.2 dirichlet 1429.4285714285713\n",
      "0.2 dirichlet 2857.8571428571427\n",
      "0.2 dirichlet 4286.285714285714\n",
      "0.2 dirichlet 5714.714285714285\n",
      "0.2 dirichlet 7143.142857142857\n",
      "0.2 dirichlet 8571.571428571428\n",
      "0.2 dirichlet 10000.0\n",
      "0.30000000000000004 jelinek 0.0\n",
      "0.30000000000000004 jelinek 0.1\n",
      "0.30000000000000004 jelinek 0.2\n",
      "0.30000000000000004 jelinek 0.30000000000000004\n",
      "0.30000000000000004 jelinek 0.4\n",
      "0.30000000000000004 jelinek 0.5\n",
      "0.30000000000000004 jelinek 0.6000000000000001\n",
      "0.30000000000000004 jelinek 0.7000000000000001\n",
      "0.30000000000000004 jelinek 0.8\n",
      "0.30000000000000004 jelinek 0.9\n",
      "0.30000000000000004 jelinek 1.0\n",
      "0.30000000000000004 dirichlet 1.0\n",
      "0.30000000000000004 dirichlet 1429.4285714285713\n",
      "0.30000000000000004 dirichlet 2857.8571428571427\n",
      "0.30000000000000004 dirichlet 4286.285714285714\n",
      "0.30000000000000004 dirichlet 5714.714285714285\n",
      "0.30000000000000004 dirichlet 7143.142857142857\n",
      "0.30000000000000004 dirichlet 8571.571428571428\n",
      "0.30000000000000004 dirichlet 10000.0\n",
      "0.4 jelinek 0.0\n",
      "0.4 jelinek 0.1\n",
      "0.4 jelinek 0.2\n",
      "0.4 jelinek 0.30000000000000004\n",
      "0.4 jelinek 0.4\n",
      "0.4 jelinek 0.5\n",
      "0.4 jelinek 0.6000000000000001\n",
      "0.4 jelinek 0.7000000000000001\n",
      "0.4 jelinek 0.8\n",
      "0.4 jelinek 0.9\n",
      "0.4 jelinek 1.0\n",
      "0.4 dirichlet 1.0\n",
      "0.4 dirichlet 1429.4285714285713\n",
      "0.4 dirichlet 2857.8571428571427\n",
      "0.4 dirichlet 4286.285714285714\n",
      "0.4 dirichlet 5714.714285714285\n",
      "0.4 dirichlet 7143.142857142857\n",
      "0.4 dirichlet 8571.571428571428\n",
      "0.4 dirichlet 10000.0\n",
      "0.5 jelinek 0.0\n",
      "0.5 jelinek 0.1\n",
      "0.5 jelinek 0.2\n",
      "0.5 jelinek 0.30000000000000004\n",
      "0.5 jelinek 0.4\n",
      "0.5 jelinek 0.5\n",
      "0.5 jelinek 0.6000000000000001\n",
      "0.5 jelinek 0.7000000000000001\n",
      "0.5 jelinek 0.8\n",
      "0.5 jelinek 0.9\n",
      "0.5 jelinek 1.0\n",
      "0.5 dirichlet 1.0\n",
      "0.5 dirichlet 1429.4285714285713\n",
      "0.5 dirichlet 2857.8571428571427\n",
      "0.5 dirichlet 4286.285714285714\n",
      "0.5 dirichlet 5714.714285714285\n",
      "0.5 dirichlet 7143.142857142857\n",
      "0.5 dirichlet 8571.571428571428\n",
      "0.5 dirichlet 10000.0\n",
      "0.6000000000000001 jelinek 0.0\n",
      "0.6000000000000001 jelinek 0.1\n",
      "0.6000000000000001 jelinek 0.2\n",
      "0.6000000000000001 jelinek 0.30000000000000004\n",
      "0.6000000000000001 jelinek 0.4\n",
      "0.6000000000000001 jelinek 0.5\n",
      "0.6000000000000001 jelinek 0.6000000000000001\n",
      "0.6000000000000001 jelinek 0.7000000000000001\n",
      "0.6000000000000001 jelinek 0.8\n",
      "0.6000000000000001 jelinek 0.9\n",
      "0.6000000000000001 jelinek 1.0\n",
      "0.6000000000000001 dirichlet 1.0\n",
      "0.6000000000000001 dirichlet 1429.4285714285713\n",
      "0.6000000000000001 dirichlet 2857.8571428571427\n",
      "0.6000000000000001 dirichlet 4286.285714285714\n",
      "0.6000000000000001 dirichlet 5714.714285714285\n",
      "0.6000000000000001 dirichlet 7143.142857142857\n",
      "0.6000000000000001 dirichlet 8571.571428571428\n",
      "0.6000000000000001 dirichlet 10000.0\n",
      "0.7000000000000001 jelinek 0.0\n",
      "0.7000000000000001 jelinek 0.1\n",
      "0.7000000000000001 jelinek 0.2\n",
      "0.7000000000000001 jelinek 0.30000000000000004\n",
      "0.7000000000000001 jelinek 0.4\n",
      "0.7000000000000001 jelinek 0.5\n",
      "0.7000000000000001 jelinek 0.6000000000000001\n",
      "0.7000000000000001 jelinek 0.7000000000000001\n",
      "0.7000000000000001 jelinek 0.8\n",
      "0.7000000000000001 jelinek 0.9\n",
      "0.7000000000000001 jelinek 1.0\n",
      "0.7000000000000001 dirichlet 1.0\n",
      "0.7000000000000001 dirichlet 1429.4285714285713\n",
      "0.7000000000000001 dirichlet 2857.8571428571427\n",
      "0.7000000000000001 dirichlet 4286.285714285714\n",
      "0.7000000000000001 dirichlet 5714.714285714285\n",
      "0.7000000000000001 dirichlet 7143.142857142857\n",
      "0.7000000000000001 dirichlet 8571.571428571428\n",
      "0.7000000000000001 dirichlet 10000.0\n",
      "0.8 jelinek 0.0\n",
      "0.8 jelinek 0.1\n",
      "0.8 jelinek 0.2\n",
      "0.8 jelinek 0.30000000000000004\n",
      "0.8 jelinek 0.4\n",
      "0.8 jelinek 0.5\n",
      "0.8 jelinek 0.6000000000000001\n",
      "0.8 jelinek 0.7000000000000001\n",
      "0.8 jelinek 0.8\n",
      "0.8 jelinek 0.9\n",
      "0.8 jelinek 1.0\n",
      "0.8 dirichlet 1.0\n",
      "0.8 dirichlet 1429.4285714285713\n",
      "0.8 dirichlet 2857.8571428571427\n",
      "0.8 dirichlet 4286.285714285714\n",
      "0.8 dirichlet 5714.714285714285\n",
      "0.8 dirichlet 7143.142857142857\n",
      "0.8 dirichlet 8571.571428571428\n",
      "0.8 dirichlet 10000.0\n",
      "0.9 jelinek 0.0\n",
      "0.9 jelinek 0.1\n",
      "0.9 jelinek 0.2\n",
      "0.9 jelinek 0.30000000000000004\n",
      "0.9 jelinek 0.4\n",
      "0.9 jelinek 0.5\n",
      "0.9 jelinek 0.6000000000000001\n",
      "0.9 jelinek 0.7000000000000001\n",
      "0.9 jelinek 0.8\n",
      "0.9 jelinek 0.9\n",
      "0.9 jelinek 1.0\n",
      "0.9 dirichlet 1.0\n",
      "0.9 dirichlet 1429.4285714285713\n",
      "0.9 dirichlet 2857.8571428571427\n",
      "0.9 dirichlet 4286.285714285714\n",
      "0.9 dirichlet 5714.714285714285\n",
      "0.9 dirichlet 7143.142857142857\n",
      "0.9 dirichlet 8571.571428571428\n",
      "0.9 dirichlet 10000.0\n",
      "1.0 jelinek 0.0\n",
      "1.0 jelinek 0.1\n",
      "1.0 jelinek 0.2\n",
      "1.0 jelinek 0.30000000000000004\n",
      "1.0 jelinek 0.4\n",
      "1.0 jelinek 0.5\n",
      "1.0 jelinek 0.6000000000000001\n",
      "1.0 jelinek 0.7000000000000001\n",
      "1.0 jelinek 0.8\n",
      "1.0 jelinek 0.9\n",
      "1.0 jelinek 1.0\n",
      "1.0 dirichlet 1.0\n",
      "1.0 dirichlet 1429.4285714285713\n",
      "1.0 dirichlet 2857.8571428571427\n",
      "1.0 dirichlet 4286.285714285714\n",
      "1.0 dirichlet 5714.714285714285\n",
      "1.0 dirichlet 7143.142857142857\n",
      "1.0 dirichlet 8571.571428571428\n",
      "1.0 dirichlet 10000.0\n"
     ]
    }
   ],
   "source": [
    "MLM_parameters_gridsearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Report on the evaluation results (using the [Evaluation notebook](1_Evaluation.ipynb)) here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the parameter settings used for the two methods and the method you used for exploring the parameter space.\n",
    "\n",
    "\n",
    "The models parameters and the field weights were decided using a grid search over the reasonable values, ie $weights \\in [0, 1]$, $k1 \\in [1, 2]$, $b \\in [0, 1]$ for BM25F and $smoothing \\in [jelinek, dirichlet]$, $ \\lambda \\in [1, 2]$, $ \\mu \\in [10, 10000]$ for MLM. Then, the values around the parameters yielding the best results were manually tested to check if some fine-tuning was possible. The parameters achieveing the highest mean accuracy precision were then tested on Kaggle.\n",
    "\n",
    "Report only the best performing setting for each model in the table below. The corresponding result files should be pushed to your repository.\n",
    "\n",
    "\n",
    "| **Method** | **Parameter settings** | **Output file** | **P@10** | **MAP** | **MRR** |\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "| BM25F | k1: 1.0, $b_{title}$: 0.2, $b_{content}$: 0.29, $w_{title}$: 0.1, $w_{content}$: 0.9 | `data/bm25_multifield.txt` | 0.2156 | 0.0802 | 0.3636 |\n",
    "| MLM | Smoothing method: jelinek, smoothing param: $\\lambda = 1.0$, $w_{title}$: 0.2, $w_{content}$: 0.8 | `data/lm_multifield.txt` | 0.1689 | 0.0542 | 0.3551 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
