{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Restaurant and Consumer datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_accepts = pd.read_csv('data/chefmozaccepts.csv')\n",
    "data_cuisine = pd.read_csv('data/chefmozcuisine.csv')\n",
    "data_hours = pd.read_csv('data/chefmozhours4.csv')\n",
    "data_parking = pd.read_csv('data/chefmozparking.csv')\n",
    "geoplaces = pd.read_csv('data/geoplaces2.csv', encoding='latin1')\n",
    "data_rating = pd.read_csv('data/rating_final.csv')\n",
    "data_user_cuisine = pd.read_csv('data/usercuisine.csv')\n",
    "user_payment = pd.read_csv('data/userpayment.csv')\n",
    "user_profile = pd.read_csv('data/userprofile.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will be using the methods below. The fisrt one replaces missing values by Numpy's NaN, and the second one computes the ratio of missing values for every column of a DataFrame. The third one replaces all the strings by their lowercase representation, so as to group related names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_missing(df):\n",
    "    return df.replace(to_replace=['?', 'None', 'none'], value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_na_ratio(df):\n",
    "    return (df.isna().sum() / len(df.index)).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_rows(df):\n",
    "    print(int(0.9*len(df.columns)))\n",
    "    return df.dropna(axis='index', thresh=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(df):\n",
    "    return df.applymap(lambda x:x.lower() if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geoplaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's clean the geographical dataset by dropping useless columns and checking if it contains any duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 duplicated rows\n"
     ]
    }
   ],
   "source": [
    "geoplaces.drop(columns=['the_geom_meter', 'fax', 'zip', 'url'], inplace=True)\n",
    "geoplaces = to_lowercase(geoplaces)\n",
    "geoplaces = normalize_missing(geoplaces)\n",
    "print(geoplaces.duplicated().sum(), \"duplicated rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has no duplicated rows, let's group all unavailable values and check if some columns aren't worth looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "placeID           0.000\n",
       "latitude          0.000\n",
       "longitude         0.000\n",
       "name              0.000\n",
       "address           0.208\n",
       "city              0.138\n",
       "state             0.138\n",
       "country           0.215\n",
       "alcohol           0.000\n",
       "smoking_area      0.538\n",
       "dress_code        0.000\n",
       "accessibility     0.000\n",
       "price             0.000\n",
       "Rambience         0.000\n",
       "franchise         0.000\n",
       "area              0.000\n",
       "other_services    0.915\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_na_ratio(geoplaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 'other services' contains more than 90% of unkwown values, so let's drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoplaces.drop(columns='other_services', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 duplicated rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "userID              0.000\n",
       "latitude            0.000\n",
       "longitude           0.000\n",
       "smoker              0.022\n",
       "drink_level         0.000\n",
       "dress_preference    0.036\n",
       "ambience            0.043\n",
       "transport           0.051\n",
       "marital_status      0.029\n",
       "hijos               0.080\n",
       "birth_year          0.000\n",
       "interest            0.217\n",
       "personality         0.000\n",
       "religion            0.217\n",
       "activity            0.051\n",
       "color               0.000\n",
       "weight              0.000\n",
       "budget              0.051\n",
       "height              0.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_profile = to_lowercase(user_profile)\n",
    "user_profile = normalize_missing(user_profile)\n",
    "print(user_profile['userID'].duplicated().sum(), \"duplicated rows\")\n",
    "columns_na_ratio(user_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made sure that each row represents a different user, as there are no duplicated userID.\n",
    "We can drop 'interest' and 'religion' columns as they both have 20% unknown values and we won't be using them in the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 duplicated rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "userID      0.0\n",
       "Upayment    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_payment = to_lowercase(user_payment)\n",
    "user_payment = normalize_missing(user_payment)\n",
    "print(user_payment.duplicated().sum(), \"duplicated rows\")\n",
    "columns_na_ratio(user_payment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DataFrame is already clean, with no missing value and no duplicated rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "What are the names of different restaurants in the state of 'tamaulipas' ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3             little pizza emilio portes gil\n",
       "4                              carnitas_mata\n",
       "6                         taqueria el amigo \n",
       "8                   pollo_frito_buenos_aires\n",
       "19                            tacos el guero\n",
       "41                    hamburguesas la perica\n",
       "73                                palomo tec\n",
       "76                        tacos correcaminos\n",
       "86             carreton de flautas y migadas\n",
       "89                        gorditas dona tota\n",
       "94                             little cesarz\n",
       "103    carnitas mata  calle 16 de septiembre\n",
       "106                       puesto de gorditas\n",
       "109    carnitas mata calle emilio portes gil\n",
       "122                                tacos abi\n",
       "123                    la perica hamburguesa\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoplaces[geoplaces['state'] == 'tamaulipas']['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "How many different customers used public transport for going to the\n",
    "restaurants?\n",
    "\n",
    "For this question, I assume each entry in 'user profile' is someone who actually went to the restaurants, as this dataset is collected from people going to restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public       82\n",
       "car owner    35\n",
       "on foot      14\n",
       "Name: transport, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_profile['transport'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 82 customers used public transport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3** What is the least popular payment method among customers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cash                   131\n",
       "bank_debit_cards        22\n",
       "visa                    17\n",
       "mastercard-eurocard      4\n",
       "american_express         3\n",
       "Name: Upayment, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_payment['Upayment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The american express is the least popular payment method, with less than 2% of payments done via this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4** How many (different) restaurants work until 19:00 in the evenings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5** Which type of cooking practice (rcuisine) is the most common among\n",
    "restaurants?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6** What is the percentage of customers who were born between 1980 and\n",
    "1990?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7** What is the percentage of students with a medium budget preferring\n",
    "walking to the restaurants?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
