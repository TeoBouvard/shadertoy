{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 4 - classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from models import MLClassifier, ParzenClassifer, KNNClassifier\n",
    "from utils import confusion_matrix, accuracy_score, error_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 classes - 2 dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.load('data/lab4.p', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first convert the data in a canonical data structutre better suited for classification. This allow us to implement [classification models](models.py) which follows the style of scikit-learn's intuitive API, and can be applied to any number of classes and dimensions. For each classification task, we can \"fit\" the model to the training data, and \"predict\" the class of unseen samples, even though \"fit\" and \"predict\" do different things for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack((X[0].T, X[1].T))\n",
    "x_test = np.vstack((Y[0].T, Y[1].T))\n",
    "\n",
    "y_train = np.concatenate([[1]*len(X[0].T), [2]*len(X[1].T)])\n",
    "y_test = np.concatenate([[1]*len(Y[0].T), [2]*len(Y[1].T)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_evaluate(desc, model):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    err_train = error_score(y_pred_train, y_train)\n",
    "    err_test = error_score(y_pred_test, y_test)\n",
    "    cm_train = confusion_matrix(y_pred_train, y_train)\n",
    "    cm_test = confusion_matrix(y_pred_test, y_test)\n",
    "    \n",
    "    names = ['Reclassification', 'Testing']\n",
    "    error = [err_train, err_test]\n",
    "    confusion = [cm_train, cm_test]\n",
    "    \n",
    "    print(desc)\n",
    "    for name, err, cm in zip(names, error, confusion):\n",
    "        print(f\"\\t{name}\")\n",
    "        print(f\"\\t\\tP( error ) = {err:.2f}\")\n",
    "        for i, p_correct in enumerate(cm.diagonal()):\n",
    "            print(f'\\t\\tP( correct | w_{i+1} ) = {p_correct:.2f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum likelihood\n",
      "\tReclassification\n",
      "\t\tP( error ) = 0.05\n",
      "\t\tP( correct | w_1 ) = 0.97 \n",
      "\t\tP( correct | w_2 ) = 0.94 \n",
      "\tTesting\n",
      "\t\tP( error ) = 0.11\n",
      "\t\tP( correct | w_1 ) = 0.93 \n",
      "\t\tP( correct | w_2 ) = 0.85 \n",
      "--------------------------------------------------\n",
      "Parzen h1 = 0.1\n",
      "\tReclassification\n",
      "\t\tP( error ) = 0.01\n",
      "\t\tP( correct | w_1 ) = 0.98 \n",
      "\t\tP( correct | w_2 ) = 1.00 \n",
      "\tTesting\n",
      "\t\tP( error ) = 0.12\n",
      "\t\tP( correct | w_1 ) = 0.91 \n",
      "\t\tP( correct | w_2 ) = 0.85 \n",
      "--------------------------------------------------\n",
      "Parzen h1 = 5.0\n",
      "\tReclassification\n",
      "\t\tP( error ) = 0.04\n",
      "\t\tP( correct | w_1 ) = 0.92 \n",
      "\t\tP( correct | w_2 ) = 1.00 \n",
      "\tTesting\n",
      "\t\tP( error ) = 0.10\n",
      "\t\tP( correct | w_1 ) = 0.88 \n",
      "\t\tP( correct | w_2 ) = 0.91 \n",
      "--------------------------------------------------\n",
      "Nearest neighbours k = 1\n",
      "\tReclassification\n",
      "\t\tP( error ) = 0.00\n",
      "\t\tP( correct | w_1 ) = 1.00 \n",
      "\t\tP( correct | w_2 ) = 1.00 \n",
      "\tTesting\n",
      "\t\tP( error ) = 0.12\n",
      "\t\tP( correct | w_1 ) = 0.93 \n",
      "\t\tP( correct | w_2 ) = 0.84 \n",
      "--------------------------------------------------\n",
      "Nearest neighbours k = 5\n",
      "\tReclassification\n",
      "\t\tP( error ) = 0.03\n",
      "\t\tP( correct | w_1 ) = 0.97 \n",
      "\t\tP( correct | w_2 ) = 0.97 \n",
      "\tTesting\n",
      "\t\tP( error ) = 0.11\n",
      "\t\tP( correct | w_1 ) = 0.93 \n",
      "\t\tP( correct | w_2 ) = 0.86 \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Maximum likelihood\" : MLClassifier(),\n",
    "    \"Parzen h1 = 0.1\" : ParzenClassifer(h=0.1),\n",
    "    \"Parzen h1 = 5.0\" : ParzenClassifer(h=5.0),\n",
    "    \"Nearest neighbours k = 1\" : KNNClassifier(k=1),\n",
    "    \"Nearest neighbours k = 5\" : KNNClassifier(k=5),\n",
    "}\n",
    "\n",
    "for desc, model in models.items():\n",
    "    train_test_evaluate(desc, model)\n",
    "    print(50 * '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check our results with scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skl ML\n",
      "\tReclassification\n",
      "\t\tP( error ) = 0.05\n",
      "\t\tP( correct | w_1 ) = 0.97 \n",
      "\t\tP( correct | w_2 ) = 0.93 \n",
      "\tTesting\n",
      "\t\tP( error ) = 0.10\n",
      "\t\tP( correct | w_1 ) = 0.93 \n",
      "\t\tP( correct | w_2 ) = 0.88 \n",
      "--------------------------------------------------\n",
      "skl KNN k = 1\n",
      "\tReclassification\n",
      "\t\tP( error ) = 0.00\n",
      "\t\tP( correct | w_1 ) = 1.00 \n",
      "\t\tP( correct | w_2 ) = 1.00 \n",
      "\tTesting\n",
      "\t\tP( error ) = 0.12\n",
      "\t\tP( correct | w_1 ) = 0.93 \n",
      "\t\tP( correct | w_2 ) = 0.84 \n",
      "--------------------------------------------------\n",
      "skl KNN k = 5\n",
      "\tReclassification\n",
      "\t\tP( error ) = 0.03\n",
      "\t\tP( correct | w_1 ) = 0.97 \n",
      "\t\tP( correct | w_2 ) = 0.97 \n",
      "\tTesting\n",
      "\t\tP( error ) = 0.11\n",
      "\t\tP( correct | w_1 ) = 0.93 \n",
      "\t\tP( correct | w_2 ) = 0.86 \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "models = {\n",
    "    \"skl ML\" : GaussianNB(var_smoothing=0),\n",
    "    \"skl KNN k = 1\" : KNeighborsClassifier(n_neighbors=1),\n",
    "    \"skl KNN k = 5\" : KNeighborsClassifier(n_neighbors=5),\n",
    "}\n",
    "\n",
    "for desc, model in models.items():\n",
    "    train_test_evaluate(desc, model)\n",
    "    print(50 * '-')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
